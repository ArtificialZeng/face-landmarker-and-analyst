# face-landmarker-and-analyst
largely borrowed from [torchlm](https://github.com/DefTruth/torchlm) but slightly difference.
# tree Structure


* [/torchlm](./torchlm) 
  * [/torchlm/models/](/torchlm/models/)
    * [/torchlm/models/pipnet/](/torchlm/models/pipnet/)
      * [_utils.py](/torchlm/models/pipnet/_utils.py)
        * func _get_meanface  #获取平均脸坐标
        * func _normalize
       


    
/home/ailab/.vscode/extensions/ms-python.vscode-pylance-2023.7.30/dist/typeshed-fallback/stdlib    

/torchlm/models/pipnet/_utils.py

# How to run

first install the environments:

'''pip install torch==1.13.1 torchvision==0.14.1 -i https://pypi.tuna.tsinghua.edu.cn/simple'''
AttributeError: module 'torchvision.transforms' has no attribute 'RandomInvert'



### Dataset Format👇
Here is an example of WFLW ，it has 98个关键点， and 98*2=196个浮点数。
```shell
data_str = "/home/ailab/ai_code/Face/torchlm/data/WFLW/converted/image/train/51--Dresses_51_Dresses_wearingdress_51_377x306y308.jpg 0.090399586 0.42573187 0.10866954 0.45795682 0.11810201 0.49187317 0.112358704 0.5261479 0.102062576 0.5600233 0.09895004 0.59456515 0.10394906 0.6289751 0.11864587 0.6620399 0.13863263 0.6937794 0.16044308 0.72494334 0.18338181 0.75571465 0.20708795 0.7862065 0.22938746 0.8171959 0.24879164 0.84911495 0.27120394 0.8800192 0.30583662 0.90467125 0.35162267 0.9179217 0.42022532 0.91769546 0.4869847 0.90579015 0.55141157 0.88870883 0.61488706 0.8699654 0.67714006 0.8493681 0.73571736 0.82417506 0.78680027 0.7921503 0.82779914 0.75376135 0.8585171 0.7109898 0.8797322 0.66550577 0.89445347 0.6187815 0.9062185 0.5716474 0.9166726 0.5243652 0.92511964 0.4768916 0.9315518 0.4292654 0.93691 0.38157433 0.08583336 0.38205332 0.1099487 0.34874526 0.13760467 0.35944146 0.16855347 0.37018812 0.20350002 0.3847052 0.20364314 0.40611112 0.16852564 0.39701334 0.13583119 0.38937926 0.10928214 0.38269636 0.3466966 0.37593037 0.4224573 0.35846964 0.5045406 0.3448282 0.58395946 0.3475304 0.67751074 0.37874666 0.58329695 0.36837193 0.5036901 0.37162507 0.42363465 0.3890207 0.3468718 0.4042326 0.29047647 0.4620563 0.2784571 0.519018 0.26945356 0.5759845 0.24568908 0.6244509 0.21133763 0.64631855 0.25202787 0.6550153 0.29439878 0.6546509 0.34395662 0.64670664 0.39424217 0.6415468 0.11732052 0.47395265 0.12136039 0.45280927 0.14442474 0.44031727 0.19954632 0.44522488 0.24136671 0.47086045 0.19530787 0.48085672 0.1465192 0.4845248 0.13096619 0.4806024 0.41206622 0.467923 0.4400826 0.4461021 0.47913224 0.4359301 0.5331365 0.44266573 0.5851641 0.45578405 0.53773683 0.47256628 0.48585963 0.47906333 0.44872755 0.47429827 0.22280231 0.730446 0.23227262 0.7061026 0.2698824 0.70511115 0.3001243 0.70638555 0.337886 0.70262116 0.43532565 0.7068016 0.53321123 0.7079137 0.46101186 0.74201196 0.38128945 0.7662735 0.29607245 0.7778026 0.26080564 0.77177525 0.23541224 0.7541943 0.2309316 0.7310489 0.2656952 0.733978 0.30065688 0.7351684 0.40235785 0.72774065 0.5031375 0.7156184 0.40222165 0.7277528 0.30038223 0.7351707 0.2655585 0.733969 0.16521847 0.46061447 0.4871009 0.45264405"
values = data_str.split(" ")
number_of_values = len(values) - 1  # Subtract 1 because the first value is the path, not a float
print(number_of_values)

...

The `annotation_path` parameter is denotes the path to a custom annotation file, the format must be:
```shell
"img0_path x0 y0 x1 y1 ... xn-1,yn-1"
"img1_path x0 y0 x1 y1 ... xn-1,yn-1"
"img2_path x0 y0 x1 y1 ... xn-1,yn-1"
"img3_path x0 y0 x1 y1 ... xn-1,yn-1"
...

这个字符串表示的是一种存储图片路径和图片上人脸关键点坐标的格式。我们逐项解析：

"img*_path"：这是图像文件的路径。

"x0/w y0/h x1/w y1/h ... xn-1/w,yn-1/h"：这是图像上人脸关键点的坐标。每个关键点由其x和y坐标表示。"x0/w"和"y0/h"表示第一个关键点的x和y坐标，"x1/w"和"y1/h"表示第二个关键点，以此类推，直到"xn-1/w"和"yn-1/h"，表示第n个关键点的坐标。

请注意，这里的坐标值已经被归一化了，也就是说，它们被除以了图像的宽度(w)和高度(h)。这种归一化的处理方法使得坐标值位于0和1之间，不依赖于原始图像的尺寸，这对于训练深度学习模型来说非常有利，因为模型通常对输入的尺度和分布有所假设。

每一行都代表一张图片的信息，包括图片的路径以及在该图片上的人脸关键点的坐标信息。每一行的格式都是相同的。

总的来说，这种格式提供了一种有效的方式来存储和传递图像数据和对应的人脸关键点数据，这对于人脸识别、人脸关键点检测等计算机视觉任务来说非常重要。
```
If the label in annotation_path is already normalized by image size, please set `coordinates_already_normalized` as `True` in `apply_training` API.
```shell
"img0_path x0/w y0/h x1/w y1/h ... xn-1/w,yn-1/h"
"img1_path x0/w y0/h x1/w y1/h ... xn-1/w,yn-1/h"
"img2_path x0/w y0/h x1/w y1/h ... xn-1/w,yn-1/h"
"img3_path x0/w y0/h x1/w y1/h ... xn-1/w,yn-1/h"
'''
309.307007 538.369019 317.857345 560.120847 322.271739 583.014395 319.583872 606.149851 314.765287 629.015727 313.308619 652.331490 315.648163 675.558182 322.526266 697.876907 331.880068 719.301121 342.087363 740.336765 352.822689 761.107391 363.917162 781.689357 374.353330 802.607217 383.434488 824.152584 393.923435 845.012933 410.131531 861.653107 431.559411 870.597153 463.665456 870.444454 494.908844 862.408332 525.060623 850.878448 554.767143 838.226630 583.901545 824.323471 611.315726 807.318180 635.222521 785.701484 654.409992 759.788921 668.785995 730.918097 678.714659 700.216404 685.604212 668.677501 691.110277 636.861987 696.002773 604.946485 699.955999 572.901835 702.966238 540.754155 705.473877 508.562683 307.170013 508.885986 318.455994 486.403046 331.398987 493.622986 345.883026 500.876984 362.238007 510.675995 362.304993 525.125000 345.869995 518.984009 330.569000 513.830994 318.144043 509.320038 429.253998 504.752991 464.710022 492.967010 503.125000 483.759033 540.293030 485.583008 584.075012 506.653992 539.982971 499.651062 502.726990 501.846924 465.261017 513.588989 429.335999 523.856995 402.942993 562.888000 397.317920 601.337128 393.104264 639.789538 381.982487 672.504378 365.906006 687.265015 384.949049 693.135309 404.778631 692.889391 427.971704 687.526973 451.505341 684.044067 321.906006 570.918030 323.796664 556.646269 334.590775 548.214155 360.387677 551.526797 379.959625 568.830811 358.404083 575.578291 335.570987 578.054240 328.292173 575.406626 459.846985 566.848022 472.958665 552.118923 491.233881 545.252822 516.507880 549.799368 540.856812 558.654236 518.660836 569.982240 494.382313 574.367759 477.004499 571.151332 371.271484 744.051025 375.703587 727.619266 393.304969 726.950019 407.458170 727.810235 425.130651 725.269288 470.732409 728.091068 516.542847 728.841736 482.753543 751.858065 445.443459 768.234622 405.561907 776.016744 389.057043 771.948271 377.172928 760.081165 375.075989 744.458008 391.345366 746.435138 407.707421 747.238678 455.303473 742.224917 502.468353 734.042419 455.239728 742.233146 407.578882 747.240243 391.281381 746.429043 344.322242 561.914769 494.963222 556.534734 306 308 696 870 0 0 1 0 0 0 51--Dresses/51_Dresses_wearingdress_51_377.jpg
579.002991 167.764008 579.682070 179.841323 580.396685 191.916578 581.180930 203.987499 582.094807 216.049139 583.382909 228.075746 585.374800 240.004224 588.420252 251.705177 592.865761 262.944478 598.939953 273.391388 606.511601 282.811170 615.344603 291.061050 625.247818 297.989407 636.045115 303.419061 647.520356 307.211122 659.426414 309.285819 671.508020 309.583742 683.397696 308.057629 694.815136 304.434759 705.151929 298.387197 714.145741 290.461426 722.197494 281.567166 729.773961 272.263211 736.507154 262.341686 741.199007 251.330175 743.021534 239.491578 743.259883 227.496097 743.381876 215.497279 744.026075 203.515218 744.802429 191.540415 745.231368 179.549244 745.005466 167.552570 744.397278 155.568115 588.348999 162.119995 600.580017 150.860016 614.056030 148.173996 629.072021 143.841995 642.203979 145.157013 642.507996 154.240997 629.622070 155.470978 614.334045 156.462021 601.320007 158.653000 686.923035 145.289001 700.271973 144.063995 712.906006 142.413010 726.325989 143.873001 740.052063 151.964005 726.577087 151.367020 713.216980 151.678009 701.228027 152.216980 687.487976 152.234009 665.974976 167.014008 666.934861 182.321631 668.026028 197.618569 668.243750 212.918750 647.796997 229.917999 658.080136 228.718214 668.270293 226.886861 678.366553 228.236924 688.525879 228.346008 607.973999 174.065002 616.356818 170.887303 624.996269 168.568987 633.428267 169.346060 640.715210 173.747437 632.801831 175.302178 624.766076 175.927228 616.322991 175.441171 692.901978 168.134995 701.248509 164.528774 710.298478 164.096382 716.295504 165.647444 721.988464 168.114059 716.453316 169.078162 710.870876 169.700697 701.829678 169.599006 634.932983 257.148987 649.822099 252.503789 664.215203 247.683742 670.933146 247.548371 676.791248 245.853122 690.083864 248.323659 703.338989 252.515854 694.821614 261.323154 683.946037 266.847230 671.793357 268.122828 659.151308 265.854177 647.163615 261.162456 641.656006 257.993988 656.269473 254.656173 671.187553 253.108325 685.033559 251.467608 698.846191 253.306091 684.830853 251.468581 670.786053 253.164524 656.068823 254.684992 624.143750 171.268750 709.587500 167.900000 586 73 746 317 0 0 1 0 0 0 19--Couple/19_Couple_Couple_19_340.jpg
...
'''
/home/ailab/ai_code/Face/torchlm/data/WFLW/converted/image/train/51--Dresses_51_Dresses_wearingdress_51_377x306y308.jpg 0.090399586 0.42573187 0.10866954 0.45795682 0.11810201 0.49187317 0.112358704 0.5261479 0.102062576 0.5600233 0.09895004 0.59456515 0.10394906 0.6289751 0.11864587 0.6620399 0.13863263 0.6937794 0.16044308 0.72494334 0.18338181 0.75571465 0.20708795 0.7862065 0.22938746 0.8171959 0.24879164 0.84911495 0.27120394 0.8800192 0.30583662 0.90467125 0.35162267 0.9179217 0.42022532 0.91769546 0.4869847 0.90579015 0.55141157 0.88870883 0.61488706 0.8699654 0.67714006 0.8493681 0.73571736 0.82417506 0.78680027 0.7921503 0.82779914 0.75376135 0.8585171 0.7109898 0.8797322 0.66550577 0.89445347 0.6187815 0.9062185 0.5716474 0.9166726 0.5243652 0.92511964 0.4768916 0.9315518 0.4292654 0.93691 0.38157433 0.08583336 0.38205332 0.1099487 0.34874526 0.13760467 0.35944146 0.16855347 0.37018812 0.20350002 0.3847052 0.20364314 0.40611112 0.16852564 0.39701334 0.13583119 0.38937926 0.10928214 0.38269636 0.3466966 0.37593037 0.4224573 0.35846964 0.5045406 0.3448282 0.58395946 0.3475304 0.67751074 0.37874666 0.58329695 0.36837193 0.5036901 0.37162507 0.42363465 0.3890207 0.3468718 0.4042326 0.29047647 0.4620563 0.2784571 0.519018 0.26945356 0.5759845 0.24568908 0.6244509 0.21133763 0.64631855 0.25202787 0.6550153 0.29439878 0.6546509 0.34395662 0.64670664 0.39424217 0.6415468 0.11732052 0.47395265 0.12136039 0.45280927 0.14442474 0.44031727 0.19954632 0.44522488 0.24136671 0.47086045 0.19530787 0.48085672 0.1465192 0.4845248 0.13096619 0.4806024 0.41206622 0.467923 0.4400826 0.4461021 0.47913224 0.4359301 0.5331365 0.44266573 0.5851641 0.45578405 0.53773683 0.47256628 0.48585963 0.47906333 0.44872755 0.47429827 0.22280231 0.730446 0.23227262 0.7061026 0.2698824 0.70511115 0.3001243 0.70638555 0.337886 0.70262116 0.43532565 0.7068016 0.53321123 0.7079137 0.46101186 0.74201196 0.38128945 0.7662735 0.29607245 0.7778026 0.26080564 0.77177525 0.23541224 0.7541943 0.2309316 0.7310489 0.2656952 0.733978 0.30065688 0.7351684 0.40235785 0.72774065 0.5031375 0.7156184 0.40222165 0.7277528 0.30038223 0.7351707 0.2655585 0.733969 0.16521847 0.46061447 0.4871009 0.45264405
/home/ailab/ai_code/Face/torchlm/data/WFLW/converted/image/train/19--Couple_19_Couple_Couple_19_340x586y73.jpg 0.04689058 0.4087509 0.050427448 0.4499704 0.0541494 0.49118286 0.05823401 0.5323805 0.06299379 0.5735465 0.06970265 0.61459297 0.08007708 0.6553045 0.09593881 0.6952395 0.1190925 0.7335989 0.15072893 0.7692539 0.1901646 0.8014033 0.2361698 0.8295599 0.28774905 0.85320616 0.34398496 0.8717374 0.40375185 0.8846796 0.4657626 0.89176047 0.5286876 0.89277726 0.590613 0.8875687 0.65007883 0.87520397 0.7039163 0.85456383 0.75075907 0.8275134 0.7926953 0.7971576 0.83215606 0.76540345 0.86722475 0.7315416 0.89166147 0.69395965 0.9011538 0.65355486 0.90239525 0.6126147 0.90303063 0.5716631 0.9063858 0.53076863 0.9104293 0.48989904 0.9126634 0.44897354 0.9114868 0.40802926 0.9083192 0.36712667 0.0955677 0.38948804 0.15927093 0.35105807 0.2294585 0.34189078 0.30766678 0.3271058 0.3760624 0.3315939 0.37764582 0.36259726 0.31053162 0.36679515 0.23090649 0.37017754 0.16312504 0.3776553 0.60897416 0.33204436 0.6784999 0.32786345 0.7443021 0.3222287 0.81419784 0.32721162 0.8856878 0.35482594 0.8155057 0.35278848 0.7459218 0.35384986 0.6834793 0.35568935 0.61191654 0.35574746 0.49986967 0.40619114 0.50486904 0.4584356 0.5105522 0.5106436 0.5116862 0.56286263 0.4051927 0.62088054 0.4587507 0.6167857 0.5118244 0.6105354 0.56440914 0.61514306 0.61732227 0.6155154 0.19778125 0.43025598 0.24144176 0.4194106 0.2864389 0.41149825 0.33035555 0.4141504 0.3683084 0.42917213 0.32709286 0.43447843 0.28523996 0.4366117 0.24126558 0.4349528 0.6401145 0.41001704 0.683586 0.39770913 0.73072124 0.39623338 0.76195574 0.4015271 0.7916066 0.4099456 0.7627777 0.41323605 0.7337025 0.41536075 0.6866129 0.41501367 0.3381926 0.7138191 0.4157401 0.69796515 0.49070418 0.6815145 0.5256935 0.68105245 0.55620444 0.6752666 0.6254368 0.6836985 0.6944739 0.69800633 0.65011257 0.7280654 0.59346896 0.74691886 0.5301737 0.75127244 0.46432972 0.7435296 0.40189382 0.7275169 0.37320837 0.71670306 0.44932017 0.7053112 0.5270185 0.7000284 0.59913313 0.6944287 0.6710739 0.7007034 0.59807736 0.694432 0.5249274 0.7002202 0.44827512 0.7054095 0.2819987 0.42071247 0.72701824 0.409215
'''
```
Here is an example of [WFLW](torchlm/data/_converters.py) to show you how to prepare the dataset, also see [test/data.py](test/data.py).


# 输出解释

Input Name: img, Input Shape: [1, 3, 256, 256] Output Names: ['outputs_cls', 'outputs_x', 'outputs_y', 'outputs_nb_x', 'outputs_nb_y'], Output Shapes: [[1, 98, 8, 8], [1, 98, 8, 8], [1, 98, 8, 8], [1, 980, 8, 8], [1, 980, 8, 8]]

在解释这个输出之前，我们首先需要了解一些背景知识。在计算机视觉和深度学习中，关键点检测是一种常见的任务，用于检测图像中某些特定对象的关键点位置，比如人脸关键点检测就是要检测人脸上的眼睛、鼻子、嘴等关键部位的位置。在训练关键点检测模型时，我们需要输入图像，然后模型会输出每个关键点的位置。

在这个例子中，输入图像的形状是 [1, 3, 256, 256]，这通常表示有1张图像（batch size为1），每张图像有3个颜色通道（RGB），图像的大小为 256x256 像素。

模型的输出包含5个部分：'outputs_cls', 'outputs_x', 'outputs_y', 'outputs_nb_x', 'outputs_nb_y'，每个部分的输出形状分别为：[1, 98, 8, 8], [1, 98, 8, 8], [1, 98, 8, 8], [1, 980, 8, 8], [1, 980, 8, 8]。

'outputs_cls': 这部分可能表示模型预测的每个关键点的置信度或类别。98可能代表预测的关键点的数量，8x8可能表示将原始图像分割成的网格的大小，每个网格都会有一个类别的预测。

'outputs_x' 和 'outputs_y': 这两部分可能表示每个关键点在x轴和y轴上的位置。98同样可能代表预测的关键点的数量，8x8可能表示将原始图像分割成的网格的大小，每个网格都会有一个坐标预测。

'outputs_nb_x' 和 'outputs_nb_y': 这两部分可能表示更高精度的坐标预测，可能通过某种方式对原始预测进行了改进或精细化。980可能表示的是某种变换或拓展后的关键点数量，8x8仍然可能表示将原始图像分割成的网格的大小。

以上解释是对模型输入输出的一种可能的理解，具体的含义还需要参考模型的设计和实现的文档或源码。
